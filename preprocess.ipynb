{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len:  30\n",
      "[\"def encrypt(string, key):\\n    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\\n        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\\n    print(str)\\n    return ''.join([chr(ch) for ch in str])\", 'def check_prime(x):\\n        if (x < 2):\\n            return False\\n        if (x == 2):\\n             return True\\n        for k in range(3, int(math.sqrt(x)), 2):\\n            if x % k == 0:\\n                return False \\n        return True', \"for word in content.split(' '):\\n    word = ''.join([ch for ch in word if ch.isalpha()])\\n    freq[word] = freq.get(word,  0) + 1\"]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open(\"dataset.json\", \"r\") as file:\n",
    "    obj = json.load(file)\n",
    "    \n",
    "print(\"Len: \", len(obj))\n",
    "print(obj[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['def encrypt(string, key):',\n",
       "  \"    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\",\n",
       "  \"        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\",\n",
       "  '    print(str)',\n",
       "  \"    return ''.join([chr(ch) for ch in str])\"],\n",
       " ['def check_prime(x):',\n",
       "  '        if (x < 2):',\n",
       "  '            return False',\n",
       "  '        if (x == 2):',\n",
       "  '             return True',\n",
       "  '        for k in range(3, int(math.sqrt(x)), 2):',\n",
       "  '            if x % k == 0:',\n",
       "  '                return False ',\n",
       "  '        return True'],\n",
       " [\"for word in content.split(' '):\",\n",
       "  \"    word = ''.join([ch for ch in word if ch.isalpha()])\",\n",
       "  '    freq[word] = freq.get(word,  0) + 1'],\n",
       " ['@app.route(\"/\")',\n",
       "  '    def index(name=None):',\n",
       "  '    return render_template(\"initial_design.html\", name=name)'],\n",
       " ['@app.route(\"/login\", methods=[\"GET\", \"POST\"])',\n",
       "  'def login():',\n",
       "  '    error_msg = \"\"',\n",
       "  '    if request.method == \"POST\":',\n",
       "  '        username = request.form.get(\"username\", \"\")',\n",
       "  '        password = request.form.get(\"password\", \"\")',\n",
       "  '        # TODO: verify credentials and set the session dict',\n",
       "  '        if username in ALLOWED_USERS and password == ALLOWED_USERS[username]:',\n",
       "  \"            session['authenticated'] = True\",\n",
       "  '            session[\"username\"] = username',\n",
       "  '        ',\n",
       "  '    return render_template(\"login.html\", error_msg=error_msg)'],\n",
       " ['@app.errorhandler(404)',\n",
       "  'def error404(code):',\n",
       "  '    # TODO_bonus: make it show a fancy HTTP 404 error page, with red background and bold message ;) ',\n",
       "  \"    return 'HTTP Error 404 - Page Not Found'\"],\n",
       " ['return {',\n",
       "  '        \"username\": session[\"username\"],',\n",
       "  '        \"is_auth\": session[\"authenticated\"],',\n",
       "  '        \"categories\": thumbimg.keys(),',\n",
       "  '        \"images\": {cat:zip(imagespercat[cat], thumbimg[cat]) for cat in thumbimg}',\n",
       "  '    }'],\n",
       " ['imagespercat = {}',\n",
       "  \"    with open(DATABASE_FILE, 'rb') as inp:\",\n",
       "  '        imagespercat = pickle.load(inp)',\n",
       "  '    return imagespercat'],\n",
       " ['model = tf.keras.models.Sequential()',\n",
       "  'model.add(tf.keras.layers.Dense(5))',\n",
       "  \"model.add(tf.keras.layers.Dense(10000, activation='relu'))\",\n",
       "  \"model.add(tf.keras.layers.Dense(1000, activation='relu'))\",\n",
       "  'model.add(tf.keras.layers.Dense(1))',\n",
       "  'loss_fn = tf.keras.losses.MeanAbsoluteError()',\n",
       "  \"model.compile(optimizer='adam', loss=loss_fn)\"],\n",
       " ['for file in os.listdir(srcPath):',\n",
       "  '    if os.path.isfile(srcPath + file):',\n",
       "  '        if not os.path.isdir(srcPath + file[:file.rfind(\".\")]):',\n",
       "  '            os.mkdir(srcPath + file[:file.rfind(\".\")])',\n",
       "  '        shutil.move(srcPath + file, srcPath + file[:file.rfind(\".\")] + \"\\\\\" + file)'],\n",
       " ['def LoadData(self):',\n",
       "  '        try:',\n",
       "  '            file = open(os.path.join(__location__, \\'save.model\\'), \"rb\")',\n",
       "  '            (self.weights, self.biases) = pickle.load(file)',\n",
       "  '        except:',\n",
       "  '            print(\"No file found!\")',\n",
       "  '            self.defaultInit()'],\n",
       " ['window = Tk()',\n",
       "  \"    window.geometry('400x180')\",\n",
       "  '    window.geometry(\"+550+300\")',\n",
       "  '    window.title(\"Path Visualization\")',\n",
       "  '    lb = Label(window, text=\"How big do you want the matrix to be?\", font=(\"Arial\", 13))',\n",
       "  '    lb.place(relx=0.5, rely=0.04, anchor=N)'],\n",
       " ['while running and Q and not found:',\n",
       "  '        ',\n",
       "  '        for event in pygame.event.get():',\n",
       "  '            if event.type == pygame.QUIT:',\n",
       "  '                running = False',\n",
       "  '        ',\n",
       "  '        if not found: ',\n",
       "  '            x, y = Q.pop()'],\n",
       " ['def valid(x, y, value, matrix):',\n",
       "  '',\n",
       "  '    for i in range(9):',\n",
       "  '        if (matrix[x][i] == value or matrix[i][y] == value) and i != x and i != y:',\n",
       "  '            return False',\n",
       "  '',\n",
       "  '    p_x = ((x // 3) * 3)',\n",
       "  '    p_y = ((y // 3) * 3)',\n",
       "  '',\n",
       "  '    for i in range(p_x, p_x + 3):',\n",
       "  '        for j in range(p_y, p_y + 3):',\n",
       "  '            if matrix[i][j] == value and (i != x or j != y):',\n",
       "  '                return False',\n",
       "  '',\n",
       "  '    return True'],\n",
       " ['def SudokuSolver(pos, R, lenR, matrix):',\n",
       "  '',\n",
       "  '    if (pos >= lenR):',\n",
       "  '        return True',\n",
       "  '',\n",
       "  '    x = R[pos][0]',\n",
       "  '    y = R[pos][1]',\n",
       "  '',\n",
       "  '    for i in range(1, 10):',\n",
       "  '        if valid(x, y, i, matrix):',\n",
       "  '',\n",
       "  '            matrix[x][y] = i',\n",
       "  '',\n",
       "  '            if (SudokuSolver(pos + 1, R, lenR, matrix)):',\n",
       "  '                return True',\n",
       "  '',\n",
       "  '            matrix[x][y] = 0',\n",
       "  '',\n",
       "  '    return False'],\n",
       " ['for i in range(1, 850):',\n",
       "  '    element = driver.find_element_by_xpath(pattern.format(miau=str(i)))',\n",
       "  '    hover = ActionChains(driver).move_to_element(element)',\n",
       "  '    hover.perform()',\n",
       "  \"    input('d')\",\n",
       "  '    driver.execute_script(\"window.scrollBy(0,125)\")',\n",
       "  \"    input('d')\"],\n",
       " [\"msg_box = driver.find_element_by_class_name('_3uMse')\",\n",
       "  'for i in range(no_of_times):',\n",
       "  '    msg_box.send_keys(msg)',\n",
       "  \"    button = driver.find_element_by_class_name('_1U1xa')\",\n",
       "  '    button.click()'],\n",
       " ['def reverse_string(s):', '    return s[::-1]'],\n",
       " ['def factorial(n):',\n",
       "  '    if n == 0 or n == 1:',\n",
       "  '        return 1',\n",
       "  '    else:',\n",
       "  '        return n * factorial(n - 1)'],\n",
       " ['def count_vowels(s):',\n",
       "  '    vowels = \"aeiouAEIOU\"',\n",
       "  '    return sum(1 for char in s if char in vowels)'],\n",
       " ['def find_max(lst):',\n",
       "  '    if not lst:',\n",
       "  '        return None',\n",
       "  '    max_value = lst[0]',\n",
       "  '    for num in lst:',\n",
       "  '        if num > max_value:',\n",
       "  '            max_value = num',\n",
       "  '    return max_value'],\n",
       " ['def celsius_to_fahrenheit(c):',\n",
       "  '    return (c * 9/5) + 32',\n",
       "  'print(celsius_to_fahrenheit(25))'],\n",
       " ['def is_palindrome(s):',\n",
       "  '    s = s.lower().replace(\" \", \"\")',\n",
       "  '    return s == s[::-1]'],\n",
       " ['def gcd(a, b):', '    while b:', '        a, b = b, a % b', '    return a'],\n",
       " ['def fibonacci(n):',\n",
       "  '    fib_seq = [0, 1]',\n",
       "  '    for i in range(2, n):',\n",
       "  '        fib_seq.append(fib_seq[-1] + fib_seq[-2])',\n",
       "  '    return fib_seq[:n]'],\n",
       " ['def flatten_list(nested_list):',\n",
       "  '    flat_list = []',\n",
       "  '    for item in nested_list:',\n",
       "  '        if isinstance(item, list):',\n",
       "  '            flat_list.extend(flatten_list(item))',\n",
       "  '        else:',\n",
       "  '            flat_list.append(item)',\n",
       "  '    return flat_list'],\n",
       " ['def sum_of_digits(n):',\n",
       "  '    return sum(int(digit) for digit in str(abs(n)))'],\n",
       " ['def remove_duplicates(lst):',\n",
       "  '    return list(set(lst))',\n",
       "  '    print(remove_duplicates([1, 2, 2, 3, 4, 4, 5]))'],\n",
       " ['def is_leap_year(year):',\n",
       "  '    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)',\n",
       "  '    print(is_leap_year(2024))'],\n",
       " ['def second_largest(lst):',\n",
       "  '    unique_lst = list(set(lst))',\n",
       "  '    if len(unique_lst) < 2:',\n",
       "  '        return None',\n",
       "  '    unique_lst.sort(reverse=True)',\n",
       "  '    return unique_lst[1]']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def split_code(code):\n",
    "    return re.findall(r'\\w+|[^\\w]', code)\n",
    "\n",
    "obj = [a.splitlines() for a in obj]\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('def encrypt(string, key):',\n",
       "  \"    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\",\n",
       "  \"        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\\n    print(str)\\n    return ''.join([chr(ch) for ch in str])\"),\n",
       " ('def check_prime(x):\\n        if (x < 2):\\n            return False\\n        if (x == 2):\\n             return True\\n        for k in range(3, int(math.sqrt(x)), 2):',\n",
       "  '            if x % k == 0:',\n",
       "  '                return False \\n        return True'),\n",
       " (\"for word in content.split(' '):\",\n",
       "  \"    word = ''.join([ch for ch in word if ch.isalpha()])\",\n",
       "  '    freq[word] = freq.get(word,  0) + 1'),\n",
       " ('@app.route(\"/\")',\n",
       "  '    def index(name=None):',\n",
       "  '    return render_template(\"initial_design.html\", name=name)'),\n",
       " ('@app.route(\"/login\", methods=[\"GET\", \"POST\"])\\ndef login():',\n",
       "  '    error_msg = \"\"',\n",
       "  '    if request.method == \"POST\":\\n        username = request.form.get(\"username\", \"\")\\n        password = request.form.get(\"password\", \"\")\\n        # TODO: verify credentials and set the session dict\\n        if username in ALLOWED_USERS and password == ALLOWED_USERS[username]:\\n            session[\\'authenticated\\'] = True\\n            session[\"username\"] = username\\n        \\n    return render_template(\"login.html\", error_msg=error_msg)'),\n",
       " ('@app.errorhandler(404)\\ndef error404(code):',\n",
       "  '    # TODO_bonus: make it show a fancy HTTP 404 error page, with red background and bold message ;) ',\n",
       "  \"    return 'HTTP Error 404 - Page Not Found'\"),\n",
       " ('return {\\n        \"username\": session[\"username\"],',\n",
       "  '        \"is_auth\": session[\"authenticated\"],',\n",
       "  '        \"categories\": thumbimg.keys(),\\n        \"images\": {cat:zip(imagespercat[cat], thumbimg[cat]) for cat in thumbimg}\\n    }'),\n",
       " ('imagespercat = {}',\n",
       "  \"    with open(DATABASE_FILE, 'rb') as inp:\",\n",
       "  '        imagespercat = pickle.load(inp)\\n    return imagespercat'),\n",
       " ('model = tf.keras.models.Sequential()\\nmodel.add(tf.keras.layers.Dense(5))',\n",
       "  \"model.add(tf.keras.layers.Dense(10000, activation='relu'))\",\n",
       "  \"model.add(tf.keras.layers.Dense(1000, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(1))\\nloss_fn = tf.keras.losses.MeanAbsoluteError()\\nmodel.compile(optimizer='adam', loss=loss_fn)\"),\n",
       " ('for file in os.listdir(srcPath):\\n    if os.path.isfile(srcPath + file):',\n",
       "  '        if not os.path.isdir(srcPath + file[:file.rfind(\".\")]):',\n",
       "  '            os.mkdir(srcPath + file[:file.rfind(\".\")])\\n        shutil.move(srcPath + file, srcPath + file[:file.rfind(\".\")] + \"\\\\\" + file)'),\n",
       " ('def LoadData(self):',\n",
       "  '        try:',\n",
       "  '            file = open(os.path.join(__location__, \\'save.model\\'), \"rb\")\\n            (self.weights, self.biases) = pickle.load(file)\\n        except:\\n            print(\"No file found!\")\\n            self.defaultInit()'),\n",
       " (\"window = Tk()\\n    window.geometry('400x180')\",\n",
       "  '    window.geometry(\"+550+300\")',\n",
       "  '    window.title(\"Path Visualization\")\\n    lb = Label(window, text=\"How big do you want the matrix to be?\", font=(\"Arial\", 13))\\n    lb.place(relx=0.5, rely=0.04, anchor=N)'),\n",
       " ('while running and Q and not found:\\n        \\n        for event in pygame.event.get():\\n            if event.type == pygame.QUIT:\\n                running = False\\n        ',\n",
       "  '        if not found: ',\n",
       "  '            x, y = Q.pop()'),\n",
       " ('def valid(x, y, value, matrix):\\n\\n    for i in range(9):\\n        if (matrix[x][i] == value or matrix[i][y] == value) and i != x and i != y:\\n            return False\\n\\n    p_x = ((x // 3) * 3)\\n    p_y = ((y // 3) * 3)\\n',\n",
       "  '    for i in range(p_x, p_x + 3):',\n",
       "  '        for j in range(p_y, p_y + 3):\\n            if matrix[i][j] == value and (i != x or j != y):\\n                return False\\n\\n    return True'),\n",
       " ('def SudokuSolver(pos, R, lenR, matrix):\\n',\n",
       "  '    if (pos >= lenR):',\n",
       "  '        return True\\n\\n    x = R[pos][0]\\n    y = R[pos][1]\\n\\n    for i in range(1, 10):\\n        if valid(x, y, i, matrix):\\n\\n            matrix[x][y] = i\\n\\n            if (SudokuSolver(pos + 1, R, lenR, matrix)):\\n                return True\\n\\n            matrix[x][y] = 0\\n\\n    return False'),\n",
       " ('for i in range(1, 850):\\n    element = driver.find_element_by_xpath(pattern.format(miau=str(i)))',\n",
       "  '    hover = ActionChains(driver).move_to_element(element)',\n",
       "  '    hover.perform()\\n    input(\\'d\\')\\n    driver.execute_script(\"window.scrollBy(0,125)\")\\n    input(\\'d\\')'),\n",
       " (\"msg_box = driver.find_element_by_class_name('_3uMse')\\nfor i in range(no_of_times):\\n    msg_box.send_keys(msg)\",\n",
       "  \"    button = driver.find_element_by_class_name('_1U1xa')\",\n",
       "  '    button.click()'),\n",
       " ('def reverse_string(s):', '    return s[::-1]', ''),\n",
       " ('def factorial(n):',\n",
       "  '    if n == 0 or n == 1:',\n",
       "  '        return 1\\n    else:\\n        return n * factorial(n - 1)'),\n",
       " ('def count_vowels(s):',\n",
       "  '    vowels = \"aeiouAEIOU\"',\n",
       "  '    return sum(1 for char in s if char in vowels)'),\n",
       " ('def find_max(lst):',\n",
       "  '    if not lst:',\n",
       "  '        return None\\n    max_value = lst[0]\\n    for num in lst:\\n        if num > max_value:\\n            max_value = num\\n    return max_value'),\n",
       " ('def celsius_to_fahrenheit(c):',\n",
       "  '    return (c * 9/5) + 32',\n",
       "  'print(celsius_to_fahrenheit(25))'),\n",
       " ('def is_palindrome(s):',\n",
       "  '    s = s.lower().replace(\" \", \"\")',\n",
       "  '    return s == s[::-1]'),\n",
       " ('def gcd(a, b):', '    while b:', '        a, b = b, a % b\\n    return a'),\n",
       " ('def fibonacci(n):',\n",
       "  '    fib_seq = [0, 1]',\n",
       "  '    for i in range(2, n):\\n        fib_seq.append(fib_seq[-1] + fib_seq[-2])\\n    return fib_seq[:n]'),\n",
       " ('def flatten_list(nested_list):',\n",
       "  '    flat_list = []',\n",
       "  '    for item in nested_list:\\n        if isinstance(item, list):\\n            flat_list.extend(flatten_list(item))\\n        else:\\n            flat_list.append(item)\\n    return flat_list'),\n",
       " ('def sum_of_digits(n):',\n",
       "  '    return sum(int(digit) for digit in str(abs(n)))',\n",
       "  ''),\n",
       " ('def remove_duplicates(lst):',\n",
       "  '    return list(set(lst))',\n",
       "  '    print(remove_duplicates([1, 2, 2, 3, 4, 4, 5]))'),\n",
       " ('def is_leap_year(year):',\n",
       "  '    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)',\n",
       "  '    print(is_leap_year(2024))'),\n",
       " ('def second_largest(lst):\\n    unique_lst = list(set(lst))',\n",
       "  '    if len(unique_lst) < 2:',\n",
       "  '        return None\\n    unique_lst.sort(reverse=True)\\n    return unique_lst[1]')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "ratio = 0.15 \n",
    "\n",
    "cs = []\n",
    "\n",
    "for code in obj: \n",
    "    l = len(code)\n",
    "    a = random.randint(1, max(l-2, 1))\n",
    "    \n",
    "    cs.append((\"\\n\".join(code[:a]), \"\\n\".join(code[a:a+1]), \"\\n\".join(code[a+1:])))\n",
    "\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_code = json.dumps(cs)\n",
    "\n",
    "with open(\"splitted2.json\", \"w\") as file:\n",
    "    file.write(splitted_code)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Adi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adi\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp311-cp311-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/199.4 MB 3.2 MB/s eta 0:01:03\n",
      "   ---------------------------------------- 0.3/199.4 MB 4.5 MB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.9/199.4 MB 8.5 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 2.1/199.4 MB 13.6 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 5.3/199.4 MB 26.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 7.0/199.4 MB 27.9 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 10.4/199.4 MB 40.9 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 11.6/199.4 MB 50.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 15.8/199.4 MB 65.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 19.3/199.4 MB 73.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 23.3/199.4 MB 81.8 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 27.3/199.4 MB 81.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 30.8/199.4 MB 81.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 34.7/199.4 MB 81.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 38.9/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 42.4/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 46.4/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 49.3/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 51.1/199.4 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 52.4/199.4 MB 54.7 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 55.8/199.4 MB 50.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 59.7/199.4 MB 65.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 63.7/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 67.2/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 71.1/199.4 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 74.7/199.4 MB 73.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 79.0/199.4 MB 93.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 83.0/199.4 MB 93.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 86.6/199.4 MB 81.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 90.5/199.4 MB 93.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 94.0/199.4 MB 93.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 98.5/199.4 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 102.4/199.4 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 106.6/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------- ----------------- 110.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 114.7/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------- --------------- 118.5/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------- --------------- 122.0/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------ -------------- 126.7/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 130.1/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 134.9/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 138.5/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 143.0/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 147.0/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 151.5/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 155.2/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 158.9/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 162.0/199.4 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 167.8/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ----- 172.6/199.4 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 176.7/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 180.8/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 185.2/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 189.3/199.4 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 193.6/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  197.7/199.4 MB 93.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  199.4/199.4 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 36.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 4.6/6.2 MB 98.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.2/6.2 MB 99.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 49.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.1 sympy-1.13.3 torch-2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Adi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['def encrypt(string, key):',\n",
       "  \"    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\",\n",
       "  \"        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\\n    print(str)\\n    return ''.join([chr(ch) for ch in str])\"],\n",
       " ['def check_prime(x):\\n        if (x < 2):\\n            return False\\n        if (x == 2):\\n             return True\\n        for k in range(3, int(math.sqrt(x)), 2):',\n",
       "  '            if x % k == 0:',\n",
       "  '                return False \\n        return True'],\n",
       " [\"for word in content.split(' '):\",\n",
       "  \"    word = ''.join([ch for ch in word if ch.isalpha()])\",\n",
       "  '    freq[word] = freq.get(word,  0) + 1'],\n",
       " ['@app.route(\"/\")',\n",
       "  '    def index(name=None):',\n",
       "  '    return render_template(\"initial_design.html\", name=name)'],\n",
       " ['@app.route(\"/login\", methods=[\"GET\", \"POST\"])\\ndef login():',\n",
       "  '    error_msg = \"\"',\n",
       "  '    if request.method == \"POST\":\\n        username = request.form.get(\"username\", \"\")\\n        password = request.form.get(\"password\", \"\")\\n        # TODO: verify credentials and set the session dict\\n        if username in ALLOWED_USERS and password == ALLOWED_USERS[username]:\\n            session[\\'authenticated\\'] = True\\n            session[\"username\"] = username\\n        \\n    return render_template(\"login.html\", error_msg=error_msg)'],\n",
       " ['@app.errorhandler(404)\\ndef error404(code):',\n",
       "  '    # TODO_bonus: make it show a fancy HTTP 404 error page, with red background and bold message ;) ',\n",
       "  \"    return 'HTTP Error 404 - Page Not Found'\"],\n",
       " ['return {\\n        \"username\": session[\"username\"],',\n",
       "  '        \"is_auth\": session[\"authenticated\"],',\n",
       "  '        \"categories\": thumbimg.keys(),\\n        \"images\": {cat:zip(imagespercat[cat], thumbimg[cat]) for cat in thumbimg}\\n    }'],\n",
       " ['imagespercat = {}',\n",
       "  \"    with open(DATABASE_FILE, 'rb') as inp:\",\n",
       "  '        imagespercat = pickle.load(inp)\\n    return imagespercat'],\n",
       " ['model = tf.keras.models.Sequential()\\nmodel.add(tf.keras.layers.Dense(5))',\n",
       "  \"model.add(tf.keras.layers.Dense(10000, activation='relu'))\",\n",
       "  \"model.add(tf.keras.layers.Dense(1000, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(1))\\nloss_fn = tf.keras.losses.MeanAbsoluteError()\\nmodel.compile(optimizer='adam', loss=loss_fn)\"],\n",
       " ['for file in os.listdir(srcPath):\\n    if os.path.isfile(srcPath + file):',\n",
       "  '        if not os.path.isdir(srcPath + file[:file.rfind(\".\")]):',\n",
       "  '            os.mkdir(srcPath + file[:file.rfind(\".\")])\\n        shutil.move(srcPath + file, srcPath + file[:file.rfind(\".\")] + \"\\\\\" + file)'],\n",
       " ['def LoadData(self):',\n",
       "  '        try:',\n",
       "  '            file = open(os.path.join(__location__, \\'save.model\\'), \"rb\")\\n            (self.weights, self.biases) = pickle.load(file)\\n        except:\\n            print(\"No file found!\")\\n            self.defaultInit()'],\n",
       " [\"window = Tk()\\n    window.geometry('400x180')\",\n",
       "  '    window.geometry(\"+550+300\")',\n",
       "  '    window.title(\"Path Visualization\")\\n    lb = Label(window, text=\"How big do you want the matrix to be?\", font=(\"Arial\", 13))\\n    lb.place(relx=0.5, rely=0.04, anchor=N)'],\n",
       " ['while running and Q and not found:\\n        \\n        for event in pygame.event.get():\\n            if event.type == pygame.QUIT:\\n                running = False\\n        ',\n",
       "  '        if not found: ',\n",
       "  '            x, y = Q.pop()'],\n",
       " ['def valid(x, y, value, matrix):\\n\\n    for i in range(9):\\n        if (matrix[x][i] == value or matrix[i][y] == value) and i != x and i != y:\\n            return False\\n\\n    p_x = ((x // 3) * 3)\\n    p_y = ((y // 3) * 3)\\n',\n",
       "  '    for i in range(p_x, p_x + 3):',\n",
       "  '        for j in range(p_y, p_y + 3):\\n            if matrix[i][j] == value and (i != x or j != y):\\n                return False\\n\\n    return True'],\n",
       " ['def SudokuSolver(pos, R, lenR, matrix):\\n',\n",
       "  '    if (pos >= lenR):',\n",
       "  '        return True\\n\\n    x = R[pos][0]\\n    y = R[pos][1]\\n\\n    for i in range(1, 10):\\n        if valid(x, y, i, matrix):\\n\\n            matrix[x][y] = i\\n\\n            if (SudokuSolver(pos + 1, R, lenR, matrix)):\\n                return True\\n\\n            matrix[x][y] = 0\\n\\n    return False'],\n",
       " ['for i in range(1, 850):\\n    element = driver.find_element_by_xpath(pattern.format(miau=str(i)))',\n",
       "  '    hover = ActionChains(driver).move_to_element(element)',\n",
       "  '    hover.perform()\\n    input(\\'d\\')\\n    driver.execute_script(\"window.scrollBy(0,125)\")\\n    input(\\'d\\')'],\n",
       " [\"msg_box = driver.find_element_by_class_name('_3uMse')\\nfor i in range(no_of_times):\\n    msg_box.send_keys(msg)\",\n",
       "  \"    button = driver.find_element_by_class_name('_1U1xa')\",\n",
       "  '    button.click()'],\n",
       " ['def reverse_string(s):', '    return s[::-1]', ''],\n",
       " ['def factorial(n):',\n",
       "  '    if n == 0 or n == 1:',\n",
       "  '        return 1\\n    else:\\n        return n * factorial(n - 1)'],\n",
       " ['def count_vowels(s):',\n",
       "  '    vowels = \"aeiouAEIOU\"',\n",
       "  '    return sum(1 for char in s if char in vowels)'],\n",
       " ['def find_max(lst):',\n",
       "  '    if not lst:',\n",
       "  '        return None\\n    max_value = lst[0]\\n    for num in lst:\\n        if num > max_value:\\n            max_value = num\\n    return max_value'],\n",
       " ['def celsius_to_fahrenheit(c):',\n",
       "  '    return (c * 9/5) + 32',\n",
       "  'print(celsius_to_fahrenheit(25))'],\n",
       " ['def is_palindrome(s):',\n",
       "  '    s = s.lower().replace(\" \", \"\")',\n",
       "  '    return s == s[::-1]'],\n",
       " ['def gcd(a, b):', '    while b:', '        a, b = b, a % b\\n    return a'],\n",
       " ['def fibonacci(n):',\n",
       "  '    fib_seq = [0, 1]',\n",
       "  '    for i in range(2, n):\\n        fib_seq.append(fib_seq[-1] + fib_seq[-2])\\n    return fib_seq[:n]'],\n",
       " ['def flatten_list(nested_list):',\n",
       "  '    flat_list = []',\n",
       "  '    for item in nested_list:\\n        if isinstance(item, list):\\n            flat_list.extend(flatten_list(item))\\n        else:\\n            flat_list.append(item)\\n    return flat_list'],\n",
       " ['def sum_of_digits(n):',\n",
       "  '    return sum(int(digit) for digit in str(abs(n)))',\n",
       "  ''],\n",
       " ['def remove_duplicates(lst):',\n",
       "  '    return list(set(lst))',\n",
       "  '    print(remove_duplicates([1, 2, 2, 3, 4, 4, 5]))'],\n",
       " ['def is_leap_year(year):',\n",
       "  '    return year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)',\n",
       "  '    print(is_leap_year(2024))'],\n",
       " ['def second_largest(lst):\\n    unique_lst = list(set(lst))',\n",
       "  '    if len(unique_lst) < 2:',\n",
       "  '        return None\\n    unique_lst.sort(reverse=True)\\n    return unique_lst[1]']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open(\"splitted2.json\", \"r\") as file:\n",
    "    cs = json.load(file)\n",
    "    \n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def encrypt(string, key):',\n",
       " \"    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\",\n",
       " \"        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\\n    print(str)\\n    return ''.join([chr(ch) for ch in str])\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigcode/tiny_starcoder_py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackbone_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_template_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     31\u001b[0m     add_end_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\chat_template_utils.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     42\u001b[0m BASIC_TYPES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:1850\u001b[0m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;66;03m# quantization depends on torch.fx\u001b[39;00m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[1;32m-> 1850\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\quantization\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\quantization\\quantize.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mhere.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     _add_observer_,\n\u001b[0;32m     12\u001b[0m     _convert,\n\u001b[0;32m     13\u001b[0m     _get_observer_dict,\n\u001b[0;32m     14\u001b[0m     _get_unique_devices_,\n\u001b[0;32m     15\u001b[0m     _is_activation_post_process,\n\u001b[0;32m     16\u001b[0m     _observer_forward_hook,\n\u001b[0;32m     17\u001b[0m     _propagate_qconfig_helper,\n\u001b[0;32m     18\u001b[0m     _register_activation_post_process_hook,\n\u001b[0;32m     19\u001b[0m     _remove_activation_post_process,\n\u001b[0;32m     20\u001b[0m     _remove_qconfig,\n\u001b[0;32m     21\u001b[0m     add_quant_dequant,\n\u001b[0;32m     22\u001b[0m     convert,\n\u001b[0;32m     23\u001b[0m     prepare,\n\u001b[0;32m     24\u001b[0m     prepare_qat,\n\u001b[0;32m     25\u001b[0m     propagate_qconfig_,\n\u001b[0;32m     26\u001b[0m     quantize,\n\u001b[0;32m     27\u001b[0m     quantize_dynamic,\n\u001b[0;32m     28\u001b[0m     quantize_qat,\n\u001b[0;32m     29\u001b[0m     swap_module,\n\u001b[0;32m     30\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\__init__.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqconfig_mapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquant_type\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization_mappings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# type: ignore[no-redef]\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize_jit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\quantization\\quantization_mappings.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintrinsic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqat\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnniqat\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantized\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnq\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantized\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreference\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnqr\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantized\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnqd\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqat\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnnqat\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\nn\\quantized\\reference\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv1d\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbeddingBag\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\nn\\quantized\\reference\\modules\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1d, Conv2d, Conv3d, ConvTranspose1d, ConvTranspose2d, ConvTranspose3d\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RNNCell, LSTMCell, GRUCell, LSTM, GRU\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\ao\\nn\\quantized\\reference\\modules\\linear.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Dict, Any\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReferenceQuantizedModule\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLinear\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mLinear, ReferenceQuantizedModule):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import csv\n",
    "\n",
    "checkpoint = \"bigcode/tiny_starcoder_py\"\n",
    "suffix = \"<fim_suffix>\"\n",
    "prefix = \"<fim_prefix>\"\n",
    "middle = \"<fim_middle>\"\n",
    "eot = \"<|endoftext|>\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "out = [\"Prefix\", \"Suffix\", \"Expected Middle\", \"Actual Middle\"]\n",
    "file = open(\"output.csv\", \"w\")\n",
    "wrt = csv.writer(file)\n",
    "wrt.writerow(out)\n",
    "\n",
    "notcsv = []\n",
    "\n",
    "for snippet in cs:\n",
    "    input = prefix + snippet[0] + suffix + snippet[2] + middle\n",
    "    # print(input, snippet[1])\n",
    "    inputs = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_new_tokens=20)\n",
    "    out = tokenizer.decode(outputs[0])\n",
    "    # wrt.writerow([snippet[0], snippet[2], snippet[1], outputs[out.find(middle) + len(middle):]])\n",
    "    notcsv.append([snippet[0], snippet[2], snippet[1], out[out.find(middle) + len(middle):]])\n",
    "    # print(outputs[out.find(middle) + len(middle):])\n",
    "    # print(outputs)\n",
    "    # out.append((snippet[0], ))\n",
    "\n",
    "\n",
    "objc = json.dumps(notcsv)\n",
    "\n",
    "with open(\"output.json\", \"w\") as file:\n",
    "    file.write(objc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cs[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading levenshtein-0.26.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
      "  Downloading rapidfuzz-3.10.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Downloading levenshtein-0.26.0-cp311-cp311-win_amd64.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.5 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 20.5/98.5 kB 320.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.2/98.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 98.5/98.5 kB 939.1 kB/s eta 0:00:00\n",
      "Downloading rapidfuzz-3.10.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.6 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 12.9 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, Levenshtein\n",
      "Successfully installed Levenshtein-0.26.0 rapidfuzz-3.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\Adi\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import Levenshtein\n",
    "\n",
    "def character_fscore(predicted, ground_truth):\n",
    "    predicted_counter = Counter(predicted)\n",
    "    ground_truth_counter = Counter(ground_truth)\n",
    "    \n",
    "    true_positives = sum((predicted_counter & ground_truth_counter).values())\n",
    "    false_positives = sum((predicted_counter - ground_truth_counter).values())\n",
    "    false_negatives = sum((ground_truth_counter - predicted_counter).values())\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    if precision + recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def is_contained(predicted, ground_truth):\n",
    "    return True if predicted in ground_truth else False \n",
    "\n",
    "def levenshtein(predicted, ground_truth):\n",
    "    return Levenshtein.distance(predicted, ground_truth)\n",
    "\n",
    "\n",
    "def jaro_similarity(s1, s2):\n",
    "    # Lengths of both strings\n",
    "    len_s1 = len(s1)\n",
    "    len_s2 = len(s2)\n",
    "\n",
    "    if len_s1 == 0 and len_s2 == 0:\n",
    "        return 1.0  # Both strings are empty, so similarity is 1.0\n",
    "\n",
    "    # Maximum distance up to which matching is allowed\n",
    "    match_distance = max(len_s1, len_s2) // 2 - 1\n",
    "\n",
    "    # Lists to store matches\n",
    "    s1_matches = [False] * len_s1\n",
    "    s2_matches = [False] * len_s2\n",
    "\n",
    "    # Count matches\n",
    "    matches = 0\n",
    "    for i in range(len_s1):\n",
    "        start = max(0, i - match_distance)\n",
    "        end = min(i + match_distance + 1, len_s2)\n",
    "        for j in range(start, end):\n",
    "            if s2_matches[j]:\n",
    "                continue\n",
    "            if s1[i] == s2[j]:\n",
    "                s1_matches[i] = True\n",
    "                s2_matches[j] = True\n",
    "                matches += 1\n",
    "                break\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Count transpositions\n",
    "    transpositions = 0\n",
    "    s2_index = 0\n",
    "    for i in range(len_s1):\n",
    "        if s1_matches[i]:\n",
    "            while not s2_matches[s2_index]:\n",
    "                s2_index += 1\n",
    "            if s1[i] != s2[s2_index]:\n",
    "                transpositions += 1\n",
    "            s2_index += 1\n",
    "\n",
    "    transpositions /= 2\n",
    "\n",
    "    # Calculate Jaro similarity\n",
    "    jaro = (matches / len_s1 + matches / len_s2 + (matches - transpositions) / matches) / 3\n",
    "    return jaro\n",
    "\n",
    "def jaro_winkler_similarity(s1, s2, p=0.1, max_prefix_length=4):\n",
    "    jaro_sim = jaro_similarity(s1, s2)\n",
    "\n",
    "    # Find the length of common prefix\n",
    "    prefix_length = 0\n",
    "    for i in range(min(len(s1), len(s2), max_prefix_length)):\n",
    "        if s1[i] == s2[i]:\n",
    "            prefix_length += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Jaro-Winkler adjustment\n",
    "    jaro_winkler_sim = jaro_sim + (prefix_length * p * (1 - jaro_sim))\n",
    "\n",
    "    return jaro_winkler_sim\n",
    "\n",
    "# Example usage\n",
    "s1 = \"martha\"\n",
    "s2 = \"marhta\"\n",
    "\n",
    "similarity = jaro_winkler_similarity(s1, s2)\n",
    "# print(f\"Jaro-Winkler similarity between '{s1}' and '{s2}': {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.json\") as file:\n",
    "    notcsv = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def encrypt(string, key):',\n",
       " \"        else (ord(chr) - ord('a') + key) % 26 + ord('a') if chr.islower() else ord(chr) for chr in string]\\n    print(str)\\n    return ''.join([chr(ch) for ch in str])\",\n",
       " \"    str = [(ord(chr) - ord('A') + key) % 26 + ord('A') if chr.isupper() == 1\",\n",
       " '\\n    if len(string) < 26:\\n        return string\\n    if len(string)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notcsv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"analysis.txt\", \"w\") as file:\n",
    "    \n",
    "    for cs in notcsv:\n",
    "        file.write(\"\\n================ Code Snippet =====================\\n\")\n",
    "        file.write(\"\\n=================== Prefix ========================\\n\")\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(cs[0])\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(\"\\n================== Expected =======================\\n\")\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(cs[2])\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(\"\\n================ Model Result =====================\\n\")\n",
    "        cs[3] = str(re.sub(r'[\\u4e00-\\u9fff]+', '', cs[3]))\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(cs[3])\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(\"\\n================== Suffix =========================\\n\")\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(cs[1])\n",
    "        file.write(\"\\n'''\\n\")\n",
    "        file.write(\"\\n================== Metrics =========================\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"Exact Match: \" + str(cs[2] == cs[3]))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"Is contained: \")\n",
    "        file.write(str(is_contained(cs[2], cs[3])))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        p, r, f = character_fscore(cs[2], cs[3])\n",
    "        file.write(\"chrf precision:\")\n",
    "        file.write(str(p))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"chrf recall:\")\n",
    "        file.write(str(r))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"chrf f1:\")\n",
    "        file.write(str(f))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"Levenshtein Distance: \")\n",
    "        file.write(str(levenshtein(cs[2], cs[3])))\n",
    "        file.write(\"\\nJaro-Winkler Similarity: \")\n",
    "        file.write(str(jaro_winkler_similarity(cs[2], cs[3])))\n",
    "        file.write(\"\\n\\nManual Review:\\n \")\n",
    "        \n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        # inca doua metrici\n",
    "        \n",
    "        file.write(\"\\n\\n\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fim_prefix>def print_one_two_three():\n",
      "    print('one')\n",
      "    <fim_suffix>\n",
      "    print('three')<fim_middle>print('two')\n",
      "    print('three')<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"<fim_prefix>def print_one_two_three():\\n    print('one')\\n    <fim_suffix>\\n    print('three')<fim_middle>\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_new_tokens = 10)\n",
    "print(tokenizer.decode(outputs[0]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
